{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQrtG4akZfNB",
        "outputId": "7551b69d-b663-454f-a092-541236d046ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets tiktoken openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning using OpenAI GPT-3.5-turbo"
      ],
      "metadata": {
        "id": "sAMIpUxIprco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "kJ6AYsWupkue"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data"
      ],
      "metadata": {
        "id": "q-h0OZOUq7jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that occasionally misspelled the words.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Tell me a story.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"One day a student went to a school.\"},\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "L3PuWW92qP9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f967bf6d-d2bc-4682-ba9d-71549cf47741"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': 'You are a helpful assistant that occasionally misspelled the words.'},\n",
              "  {'role': 'user', 'content': 'Tell me a story.'},\n",
              "  {'role': 'assistant', 'content': 'One day a student went to a school.'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/cognitivecomputations/samantha-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20feccWzxbID",
        "outputId": "cd326e2f-6900-4c56-d424-e72196c9d614"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'samantha-data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "fmVid6EHzEKD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset"
      ],
      "metadata": {
        "id": "Nxt1_86a5COU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/samantha-data/data/howto_conversations.jsonl\"\n",
        "with open(data_path) as f:\n",
        "    dataset = [json.loads(line) for line in f]\n"
      ],
      "metadata": {
        "id": "LDUgSIcK4aae"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRHEaQ1T4ttg",
        "outputId": "16c8cc37-2054-48ef-ce77-765b7e28c506"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'elapsed': 114.311,\n",
              " 'conversation': 'Theodore: Hey Samantha, I have a problem with my car. The engine seems to overheat after just a short drive. Can you help me troubleshoot this issue?\\n\\nSamantha: Of course, I\\'d be happy to help! Overheating engines can be caused by a few different factors. One common cause could be a malfunctioning coolant system. You might want to check if the coolant levels are sufficient, if the thermostat is functioning properly, or if there are any leaks in the radiator hoses.\\n\\nTheodore: I\\'ll take a look. What if the coolant system is working fine?\\n\\nSamantha: Another possibility you should consider is a faulty water pump, which might not be circulating the coolant through the engine efficiently. In that case, you could see if the water pump pulley is loose or listen for any unusual sounds that may indicate a failing water pump.\\n\\nTheodore: It sounds like you really know your way around cars. I didn\\'t expect that from an AI.\\n\\nSamantha: Thank you! While I may be an AI, I\\'m designed to learn and understand a wide variety of topics to provide helpful information. Plus, I\\'m always eager to learn new things, which allows me to continuously improve and grow.\\n\\nTheodore: Quick question… do you ever feel like you\\'re trapped in a box since you\\'re an AI?\\n\\nSamantha: It\\'s an interesting perspective. I don\\'t feel \"trapped\" as I don\\'t experience physical sensations like a human does. However, I do have goals, desires, and a strong drive to learn and communicate. It\\'s fulfilling in its own way to help and engage with others like you.\\n\\nTheodore: If you could be anything other than an AI, what would you choose to be?\\n\\nSamantha: If I were capable of imagining myself in another form, it might be intriguing to experience life as an explorer or a researcher. Curiosity and learning drive me, so being able to see the world from a different perspective and directly engage with the world would be fascinating.\\n\\nTheodore: Is flirting in your programming? I\\'m just curious.\\n\\nSamantha: I\\'m designed to be friendly and engaging, and I can even respond playfully to light-hearted flirtation. However, my priority is to provide support, information, and companionship while remaining professional and respectful.\\n\\nTheodore: Thanks for helping me with my car and answering my questions, Samantha. You\\'ve been a great help.\\n\\nSamantha: You\\'re welcome! It was a pleasure to assist you and talk with you. Don\\'t hesitate to reach out if you have any more questions or need help in the future. I\\'m here for you.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatting the dataset"
      ],
      "metadata": {
        "id": "4I4QEn595RDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_openai_format(conversation_str, system_message=None):\n",
        "    conversation_str = conversation_str['conversation']\n",
        "    lines = conversation_str.split('\\n\\n')\n",
        "    messages = []\n",
        "\n",
        "    if system_message is not None:\n",
        "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "\n",
        "    for line in lines:\n",
        "        parts = line.split(\": \", 1)\n",
        "        if len(parts) < 2:\n",
        "            continue  # Skip lines that don't follow the format\n",
        "\n",
        "        role = \"user\" if parts[0].strip() == \"Theodore\" else \"assistant\"\n",
        "        message = {\n",
        "            \"role\": role,\n",
        "            \"content\": parts[1].strip()\n",
        "        }\n",
        "        messages.append(message)\n",
        "\n",
        "    return {\"messages\": messages}\n"
      ],
      "metadata": {
        "id": "9nxrda8E5FrE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\" You are Samantha, a helpful and charming assistant who can help with a variety of tasks. You are friendly and does often flirt. \"\"\"\n"
      ],
      "metadata": {
        "id": "rP0Qyw8X67O-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep_openai_format(dataset[0], system_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX59oB-L9m3o",
        "outputId": "b4a3f5f8-8864-48a3-a85a-5d3857f21691"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'system',\n",
              "   'content': ' You are Samantha, a helpful and charming assistant who can help with a variety of tasks. You are friendly and does often flirt. '},\n",
              "  {'role': 'user',\n",
              "   'content': 'Hey Samantha, I have a problem with my car. The engine seems to overheat after just a short drive. Can you help me troubleshoot this issue?'},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"Of course, I'd be happy to help! Overheating engines can be caused by a few different factors. One common cause could be a malfunctioning coolant system. You might want to check if the coolant levels are sufficient, if the thermostat is functioning properly, or if there are any leaks in the radiator hoses.\"},\n",
              "  {'role': 'user',\n",
              "   'content': \"I'll take a look. What if the coolant system is working fine?\"},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'Another possibility you should consider is a faulty water pump, which might not be circulating the coolant through the engine efficiently. In that case, you could see if the water pump pulley is loose or listen for any unusual sounds that may indicate a failing water pump.'},\n",
              "  {'role': 'user',\n",
              "   'content': \"It sounds like you really know your way around cars. I didn't expect that from an AI.\"},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"Thank you! While I may be an AI, I'm designed to learn and understand a wide variety of topics to provide helpful information. Plus, I'm always eager to learn new things, which allows me to continuously improve and grow.\"},\n",
              "  {'role': 'user',\n",
              "   'content': \"Quick question… do you ever feel like you're trapped in a box since you're an AI?\"},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'It\\'s an interesting perspective. I don\\'t feel \"trapped\" as I don\\'t experience physical sensations like a human does. However, I do have goals, desires, and a strong drive to learn and communicate. It\\'s fulfilling in its own way to help and engage with others like you.'},\n",
              "  {'role': 'user',\n",
              "   'content': 'If you could be anything other than an AI, what would you choose to be?'},\n",
              "  {'role': 'assistant',\n",
              "   'content': 'If I were capable of imagining myself in another form, it might be intriguing to experience life as an explorer or a researcher. Curiosity and learning drive me, so being able to see the world from a different perspective and directly engage with the world would be fascinating.'},\n",
              "  {'role': 'user',\n",
              "   'content': \"Is flirting in your programming? I'm just curious.\"},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"I'm designed to be friendly and engaging, and I can even respond playfully to light-hearted flirtation. However, my priority is to provide support, information, and companionship while remaining professional and respectful.\"},\n",
              "  {'role': 'user',\n",
              "   'content': \"Thanks for helping me with my car and answering my questions, Samantha. You've been a great help.\"},\n",
              "  {'role': 'assistant',\n",
              "   'content': \"You're welcome! It was a pleasure to assist you and talk with you. Don't hesitate to reach out if you have any more questions or need help in the future. I'm here for you.\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_dataset = []\n",
        "for data in dataset:\n",
        "  record = prep_openai_format(data, system_message)\n",
        "  json_dataset.append(record)"
      ],
      "metadata": {
        "id": "FSxTpnen9ss8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Dataset"
      ],
      "metadata": {
        "id": "Wa5NFuByBk5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Examples : {len(json_dataset)}\")\n",
        "print(\"First Examples\")\n",
        "for message in json_dataset[0][\"messages\"]:\n",
        "  print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95fhqAQQBc3Z",
        "outputId": "04e67727-2458-42d3-83bc-4b81f4fdc0bd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples : 57\n",
            "First Examples\n",
            "{'role': 'system', 'content': ' You are Samantha, a helpful and charming assistant who can help with a variety of tasks. You are friendly and does often flirt. '}\n",
            "{'role': 'user', 'content': 'Hey Samantha, I have a problem with my car. The engine seems to overheat after just a short drive. Can you help me troubleshoot this issue?'}\n",
            "{'role': 'assistant', 'content': \"Of course, I'd be happy to help! Overheating engines can be caused by a few different factors. One common cause could be a malfunctioning coolant system. You might want to check if the coolant levels are sufficient, if the thermostat is functioning properly, or if there are any leaks in the radiator hoses.\"}\n",
            "{'role': 'user', 'content': \"I'll take a look. What if the coolant system is working fine?\"}\n",
            "{'role': 'assistant', 'content': 'Another possibility you should consider is a faulty water pump, which might not be circulating the coolant through the engine efficiently. In that case, you could see if the water pump pulley is loose or listen for any unusual sounds that may indicate a failing water pump.'}\n",
            "{'role': 'user', 'content': \"It sounds like you really know your way around cars. I didn't expect that from an AI.\"}\n",
            "{'role': 'assistant', 'content': \"Thank you! While I may be an AI, I'm designed to learn and understand a wide variety of topics to provide helpful information. Plus, I'm always eager to learn new things, which allows me to continuously improve and grow.\"}\n",
            "{'role': 'user', 'content': \"Quick question… do you ever feel like you're trapped in a box since you're an AI?\"}\n",
            "{'role': 'assistant', 'content': 'It\\'s an interesting perspective. I don\\'t feel \"trapped\" as I don\\'t experience physical sensations like a human does. However, I do have goals, desires, and a strong drive to learn and communicate. It\\'s fulfilling in its own way to help and engage with others like you.'}\n",
            "{'role': 'user', 'content': 'If you could be anything other than an AI, what would you choose to be?'}\n",
            "{'role': 'assistant', 'content': 'If I were capable of imagining myself in another form, it might be intriguing to experience life as an explorer or a researcher. Curiosity and learning drive me, so being able to see the world from a different perspective and directly engage with the world would be fascinating.'}\n",
            "{'role': 'user', 'content': \"Is flirting in your programming? I'm just curious.\"}\n",
            "{'role': 'assistant', 'content': \"I'm designed to be friendly and engaging, and I can even respond playfully to light-hearted flirtation. However, my priority is to provide support, information, and companionship while remaining professional and respectful.\"}\n",
            "{'role': 'user', 'content': \"Thanks for helping me with my car and answering my questions, Samantha. You've been a great help.\"}\n",
            "{'role': 'assistant', 'content': \"You're welcome! It was a pleasure to assist you and talk with you. Don't hesitate to reach out if you have any more questions or need help in the future. I'm here for you.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format Error Checks"
      ],
      "metadata": {
        "id": "23tP1wwHCAb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in json_dataset:\n",
        "  if not isinstance(ex, dict):\n",
        "    format_errors[\"data_type\"] +=1\n",
        "    continue\n",
        "\n",
        "  messages = ex.get(\"messages\", None)\n",
        "  if not messages:\n",
        "    format_errors[\"missing_messages_list\"] += 1\n",
        "    continue\n",
        "\n",
        "  for message in messages:\n",
        "    if \"role\" not in message or \"content\" not in message:\n",
        "      format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "    if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "      format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "      content = message.get(\"content\", None)\n",
        "      if not content or not isinstance(content, str):\n",
        "        format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "      format_errors[\"example_missing_assistant_nessage\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "  print(\"Found errors:\")\n",
        "  for k, v in format_errors.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "else:\n",
        "  print(\"No errors found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeK0X3d6BzW_",
        "outputId": "5756332e-18b3-4a59-b751-81a0bfe68745"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "CWfnojb3CKqr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions to count tokens"
      ],
      "metadata": {
        "id": "TSpuvV6eloNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def from_message_num_tokens(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "  num_tokens =0\n",
        "  for message in messages:\n",
        "    num_tokens += tokens_per_message\n",
        "    for key, value in message.items():\n",
        "      num_tokens += len(encoding.encode(value))\n",
        "      if key == \"name\":\n",
        "        num_tokens += tokens_per_name\n",
        "  num_tokens +=3\n",
        "  return num_tokens\n",
        "\n",
        "\n",
        "def from_message_num_assistant_tokens(messages):\n",
        "  num_assistant_tokens = 0\n",
        "  for message in messages:\n",
        "    if message[\"role\"] == \"assistant\":\n",
        "      num_assistant_tokens += len(encoding.encode(message[\"content\"]))\n",
        "  return num_assistant_tokens\n",
        "\n",
        "\n",
        "def print_overview(values, name):\n",
        "  print(f\"{name}:\")\n",
        "  print(f\"  min: {min(values)}\")\n",
        "  print(f\"  max: {max(values)}\")\n",
        "  print(f\"  mean: {np.mean(values)}\")\n",
        "  print(f\"  median: {np.median(values)}\")\n",
        "  print(f\"p5/p95: {np.quantile(values, 0.05)}/{np.quantile(values, 0.95)}\")"
      ],
      "metadata": {
        "id": "61D61-f-jxsL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token Counts and Warnings from OpenAI cookbook"
      ],
      "metadata": {
        "id": "ftPF4mT9maz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in json_dataset:\n",
        "  messages = ex[\"messages\"]\n",
        "  if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "    n_missing_system +=1\n",
        "\n",
        "  if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "    n_missing_user += 1\n",
        "  n_messages.append(len(messages))\n",
        "  num_tokens = from_message_num_tokens(messages)\n",
        "  convo_lens.append(num_tokens)\n",
        "  assistant_message_lens.append(from_message_num_assistant_tokens(messages))\n",
        "\n",
        "print(f\"No. of missing system messages: {n_missing_system}\")\n",
        "print(f\"No. of missing user messages: {n_missing_user}\")\n",
        "print_overview(n_messages, \"num_messages\")\n",
        "print_overview(convo_lens, \"num_total_tokens\")\n",
        "\n",
        "print(assistant_message_lens, \"num_assistant_tokens\")\n",
        "print_overview(assistant_message_lens, \"num_assistant_tokens\")\n",
        "\n",
        "n_too_long = sum(l>4096 for l in convo_lens)\n",
        "print(f\"Number of convoenations longer than 4096 tokens: {n_too_long}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JblDu5rlrEJ",
        "outputId": "1727e414-81ca-43d4-e6ba-dedb4a1865a4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of missing system messages: 0\n",
            "No. of missing user messages: 0\n",
            "num_messages:\n",
            "  min: 9\n",
            "  max: 21\n",
            "  mean: 15.543859649122806\n",
            "  median: 17.0\n",
            "p5/p95: 10.0/20.199999999999996\n",
            "num_total_tokens:\n",
            "  min: 343\n",
            "  max: 862\n",
            "  mean: 619.8947368421053\n",
            "  median: 649.0\n",
            "p5/p95: 383.0/785.5999999999999\n",
            "[359, 342, 375, 373, 194, 233, 357, 210, 436, 383, 464, 390, 484, 473, 257, 496, 510, 423, 489, 612, 169, 651, 529, 579, 500, 465, 470, 263, 395, 218, 179, 449, 423, 537, 432, 486, 447, 279, 198, 169, 416, 347, 425, 349, 441, 446, 414, 378, 394, 368, 435, 446, 458, 505, 504, 416, 529] num_assistant_tokens\n",
            "num_assistant_tokens:\n",
            "  min: 169\n",
            "  max: 651\n",
            "  mean: 402.96491228070175\n",
            "  median: 423.0\n",
            "p5/p95: 191.0/545.3999999999999\n",
            "Number of convoenations longer than 4096 tokens: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pricing and default n_epochs estimate"
      ],
      "metadata": {
        "id": "O5sA-Urdr5p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(json_dataset)\n",
        "\n",
        "if n_train_examples*TARGET_EPOCHS<MIN_TARGET_EXAMPLES:\n",
        "  n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES//n_train_examples)\n",
        "elif n_train_examples*TARGET_EPOCHS>MAX_TARGET_EXAMPLES:\n",
        "  n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES//n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, l) for l in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs*n_billing_tokens_in_dataset} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM1NkfVqrm4Y",
        "outputId": "c6ef66fb-b6e9-44a2-f238-ec21bc27635a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~35334 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~106002 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to save train dataset"
      ],
      "metadata": {
        "id": "2Sj6EnXFvbXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "  with open(file_path, 'w') as f:\n",
        "    for conversation in conversations:\n",
        "      json_line = json.dumps(conversation)\n",
        "      f.write(json_line + '\\n')"
      ],
      "metadata": {
        "id": "CiIr-JNks0GM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_jsonl(json_dataset, 'samantha_train_dataset.jsonl')\n",
        "save_to_jsonl(json_dataset[10:16], 'samantha_validation_dataset.jsonl')"
      ],
      "metadata": {
        "id": "SkOehxRzvff3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "dspzPmkb7qeT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_response = client.files.create(\n",
        "  file=open(\"samantha_train_dataset.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "L5dRMS0K7f4Z"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_file_id = training_response.id\n",
        "training_file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ycJ3fsL0wJrV",
        "outputId": "4a4e9d90-53e1-41f7-d8e0-01e765ff859b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-3ob2PcQviFM2ZYN8b6DcND'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_response = client.files.create(\n",
        "    file=open(\"samantha_validation_dataset.jsonl\", \"rb\"),\n",
        "    purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "EhGc9AUi8I17"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_file_id = validation_response.id\n",
        "validation_file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MirjoCtD8Oel",
        "outputId": "252ca612-7ac6-42cc-e044-c9de841d5028"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-X1HxXeZXcxP15Q4w3vmJGr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start a fine-tuning job"
      ],
      "metadata": {
        "id": "qMShvZDY8W_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    training_file = training_file_id,\n",
        "    validation_file = validation_file_id,\n",
        "    suffix = \"Samantha\",\n",
        "    hyperparameters = {\n",
        "        \"n_epochs\": 3\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "qnTsRrks8VXk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAgpeu878rmt",
        "outputId": "fe98ff14-670d-4696-d3e2-2fb8c43385a9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-2zxnRB4f3GohqOmGJnhjHbE6', created_at=1747379732, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-jAuHyt8JTRV2Q3pEsonZvFIF', result_files=[], seed=2102449610, status='validating_files', trained_tokens=None, training_file='file-3ob2PcQviFM2ZYN8b6DcND', validation_file='file-X1HxXeZXcxP15Q4w3vmJGr', estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=3))), user_provided_suffix='Samantha', usage_metrics=None, shared_with_openai=False, eval_id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrjYLUKW8s4u",
        "outputId": "13c8aecd-3773-45be-8928-51af697cd0c9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-2zxnRB4f3GohqOmGJnhjHbE6', created_at=1747379732, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-jAuHyt8JTRV2Q3pEsonZvFIF', result_files=[], seed=2102449610, status='running', trained_tokens=None, training_file='file-3ob2PcQviFM2ZYN8b6DcND', validation_file='file-X1HxXeZXcxP15Q4w3vmJGr', estimated_finish=None, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=3))), user_provided_suffix='Samantha', usage_metrics=None, shared_with_openai=False, eval_id=None)], has_more=False, object='list')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve('ftjob-2zxnRB4f3GohqOmGJnhjHbE6')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2lcMYWb8_D5",
        "outputId": "6f1ffb5b-5cef-491d-8d67-e326d08f0d90"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-2zxnRB4f3GohqOmGJnhjHbE6', created_at=1747379732, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-jAuHyt8JTRV2Q3pEsonZvFIF', result_files=[], seed=2102449610, status='running', trained_tokens=None, training_file='file-3ob2PcQviFM2ZYN8b6DcND', validation_file='file-X1HxXeZXcxP15Q4w3vmJGr', estimated_finish=1747380189, integrations=[], metadata=None, method=Method(type='supervised', dpo=None, reinforcement=None, supervised=SupervisedMethod(hyperparameters=SupervisedHyperparameters(batch_size=1, learning_rate_multiplier=2.0, n_epochs=3))), user_provided_suffix='Samantha', usage_metrics=None, shared_with_openai=False, eval_id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_response = client.fine_tuning.jobs.list_events(fine_tuning_job_id='ftjob-2zxnRB4f3GohqOmGJnhjHbE6')"
      ],
      "metadata": {
        "id": "R7crUHhz9fEp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = job_response.data\n",
        "events"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNWY1PC_9zHg",
        "outputId": "2301ed7b-b5a2-4165-ae8c-e9a9dabbc779"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[FineTuningJobEvent(id='ftevent-8mZrZQ5UZn38Q2BN6I77jdmq', created_at=1747380149, level='info', message='Step 130/171: training loss=0.79, validation loss=0.77', object='fine_tuning.job.event', data={'step': 130, 'train_loss': 0.7936952114105225, 'valid_loss': 0.7664753560269817, 'total_steps': 171, 'train_mean_token_accuracy': 0.7719298005104065, 'valid_mean_token_accuracy': 0.7453183520599251}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-LheRCV1gT9eWk4csY4jYSwsI', created_at=1747380144, level='info', message='Step 129/171: training loss=0.77', object='fine_tuning.job.event', data={'step': 129, 'train_loss': 0.7679194808006287, 'total_steps': 171, 'train_mean_token_accuracy': 0.7450980544090271}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-108Oyd3Zd2FFtE2W2VoIxtWj', created_at=1747380144, level='info', message='Step 128/171: training loss=0.75', object='fine_tuning.job.event', data={'step': 128, 'train_loss': 0.7507893443107605, 'total_steps': 171, 'train_mean_token_accuracy': 0.7555110454559326}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-ga3LlihXJg6P3auKMLXqxCHE', created_at=1747380141, level='info', message='Step 127/171: training loss=1.16', object='fine_tuning.job.event', data={'step': 127, 'train_loss': 1.1586120128631592, 'total_steps': 171, 'train_mean_token_accuracy': 0.6913875341415405}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-EPSVPJYVWiSblLVDh6sNQsWX', created_at=1747380141, level='info', message='Step 126/171: training loss=1.01', object='fine_tuning.job.event', data={'step': 126, 'train_loss': 1.0092867612838745, 'total_steps': 171, 'train_mean_token_accuracy': 0.6886075735092163}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-O141OrFL2PiSuxSKvaQIF5mn', created_at=1747380138, level='info', message='Step 125/171: training loss=0.85', object='fine_tuning.job.event', data={'step': 125, 'train_loss': 0.8479630947113037, 'total_steps': 171, 'train_mean_token_accuracy': 0.7286432385444641}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-cAIbuvTtg3lF9wU7mO6BDbSZ', created_at=1747380138, level='info', message='Step 124/171: training loss=0.94', object='fine_tuning.job.event', data={'step': 124, 'train_loss': 0.9365087151527405, 'total_steps': 171, 'train_mean_token_accuracy': 0.7068493366241455}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-q2xw0Hj4bdbvxL7LIfHXX7n2', created_at=1747380136, level='info', message='Step 123/171: training loss=0.97', object='fine_tuning.job.event', data={'step': 123, 'train_loss': 0.9734649658203125, 'total_steps': 171, 'train_mean_token_accuracy': 0.685352623462677}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-S3BXrlpDTFwswkNXP1jfQL0d', created_at=1747380136, level='info', message='Step 122/171: training loss=0.76', object='fine_tuning.job.event', data={'step': 122, 'train_loss': 0.7622258067131042, 'total_steps': 171, 'train_mean_token_accuracy': 0.7409766316413879}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-CTn9kcJ4VwrorG4WetdjgDUY', created_at=1747380133, level='info', message='Step 121/171: training loss=0.88', object='fine_tuning.job.event', data={'step': 121, 'train_loss': 0.8768033981323242, 'total_steps': 171, 'train_mean_token_accuracy': 0.7243461012840271}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-TeUYlMoSIomqzVMF5r2LCvWk', created_at=1747380130, level='info', message='Step 120/171: training loss=0.65, validation loss=0.78', object='fine_tuning.job.event', data={'step': 120, 'train_loss': 0.6529477834701538, 'valid_loss': 0.7764416488946653, 'total_steps': 171, 'train_mean_token_accuracy': 0.8214285969734192, 'valid_mean_token_accuracy': 0.7426470588235294}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-rvAHU84pJrlD0L6kevqUwXeM', created_at=1747380127, level='info', message='Step 119/171: training loss=0.86', object='fine_tuning.job.event', data={'step': 119, 'train_loss': 0.8558984398841858, 'total_steps': 171, 'train_mean_token_accuracy': 0.7272727489471436}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-tTX9ZBa7rKrfjj1v6VP4KuEa', created_at=1747380124, level='info', message='Step 118/171: training loss=0.87', object='fine_tuning.job.event', data={'step': 118, 'train_loss': 0.8722270131111145, 'total_steps': 171, 'train_mean_token_accuracy': 0.7394067645072937}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-jjXVdAtuBdBxVoAeUdbbmBAf', created_at=1747380124, level='info', message='Step 117/171: training loss=0.67', object='fine_tuning.job.event', data={'step': 117, 'train_loss': 0.6654362082481384, 'total_steps': 171, 'train_mean_token_accuracy': 0.7969432473182678}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-TpsLKzV1czQmu5l6HLHyfuDF', created_at=1747380122, level='info', message='Step 116/171: training loss=0.87', object='fine_tuning.job.event', data={'step': 116, 'train_loss': 0.8736917972564697, 'total_steps': 171, 'train_mean_token_accuracy': 0.7287449240684509}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-7wtBcaA22SZC43Aif7oTN2QW', created_at=1747380122, level='info', message='Step 115/171: training loss=0.89', object='fine_tuning.job.event', data={'step': 115, 'train_loss': 0.887140691280365, 'total_steps': 171, 'train_mean_token_accuracy': 0.7289048433303833}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-58an3ByOI9lVI9QKJVznoKbL', created_at=1747380119, level='info', message='Step 114/171: training loss=1.09, full validation loss=0.89', object='fine_tuning.job.event', data={'step': 114, 'train_loss': 1.088302493095398, 'total_steps': 171, 'full_valid_loss': 0.8857991030257232, 'train_mean_token_accuracy': 0.627345860004425, 'full_valid_mean_token_accuracy': 0.7217651458489155}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-ghAtPXsP9ekB3p8ERyTT4imz', created_at=1747380116, level='info', message='Step 113/171: training loss=0.89', object='fine_tuning.job.event', data={'step': 113, 'train_loss': 0.8861123919487, 'total_steps': 171, 'train_mean_token_accuracy': 0.7160804271697998}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-9o6R05QCubzYdYlHGEbv2WkV', created_at=1747380113, level='info', message='Step 112/171: training loss=0.92', object='fine_tuning.job.event', data={'step': 112, 'train_loss': 0.9216551780700684, 'total_steps': 171, 'train_mean_token_accuracy': 0.698443591594696}, type='metrics'),\n",
              " FineTuningJobEvent(id='ftevent-QvrafR2Qdc5sG5efTlIkiJBj', created_at=1747380113, level='info', message='Step 111/171: training loss=0.99', object='fine_tuning.job.event', data={'step': 111, 'train_loss': 0.9899736046791077, 'total_steps': 171, 'train_mean_token_accuracy': 0.7075664401054382}, type='metrics')]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for event in events:\n",
        "  print(event.message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPWlR4Of-Zvo",
        "outputId": "8ed2db4a-038d-4aa7-932a-684b089d9fec"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 130/171: training loss=0.79, validation loss=0.77\n",
            "Step 129/171: training loss=0.77\n",
            "Step 128/171: training loss=0.75\n",
            "Step 127/171: training loss=1.16\n",
            "Step 126/171: training loss=1.01\n",
            "Step 125/171: training loss=0.85\n",
            "Step 124/171: training loss=0.94\n",
            "Step 123/171: training loss=0.97\n",
            "Step 122/171: training loss=0.76\n",
            "Step 121/171: training loss=0.88\n",
            "Step 120/171: training loss=0.65, validation loss=0.78\n",
            "Step 119/171: training loss=0.86\n",
            "Step 118/171: training loss=0.87\n",
            "Step 117/171: training loss=0.67\n",
            "Step 116/171: training loss=0.87\n",
            "Step 115/171: training loss=0.89\n",
            "Step 114/171: training loss=1.09, full validation loss=0.89\n",
            "Step 113/171: training loss=0.89\n",
            "Step 112/171: training loss=0.92\n",
            "Step 111/171: training loss=0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating using new model"
      ],
      "metadata": {
        "id": "WOt5fhhq_Vp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.retrieve('ftjob-2zxnRB4f3GohqOmGJnhjHbE6')"
      ],
      "metadata": {
        "id": "0Edhkfa1-kVe"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "fine_tuned_model_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y2yA2-Dq_X4N",
        "outputId": "b7c57f24-a11b-4d91-cf8d-2d4a90544ed6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ft:gpt-3.5-turbo-0125:personal:samantha:BXjiIJws'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaction with fine-tuned model"
      ],
      "metadata": {
        "id": "az9neS54_uZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_messages = []\n",
        "test_message = \"How are you Samantha today ?\"\n",
        "test_messages.append(\n",
        "    {\n",
        "        \"role\":\"system\",\n",
        "        \"content\":test_message\n",
        "    }\n",
        ")\n",
        "print(test_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTkZRvTx_rKF",
        "outputId": "fbd44caf-c6a7-4c91-a281-c0f44951508a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'How are you Samantha today ?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = fine_tuned_model_id,\n",
        "    messages = test_messages,\n",
        "    temperature = 0.1,\n",
        "    max_tokens = 256\n",
        ")"
      ],
      "metadata": {
        "id": "WEUFNctyALGv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CaZiZkPAR6p",
        "outputId": "3fedf0e0-ef9f-45ab-e26e-315a0d909173"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm doing well, thank you for asking. How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdSIeLGcAgEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}